import streamlit as st
import cloudscraper
from bs4 import BeautifulSoup
import datetime
import time
import streamlit.components.v1 as components

# --- [1. ìŠ¤ë§ˆíŠ¸ ë‚ ì§œ ê³„ì‚° í•¨ìˆ˜ (2025-2029 ê³µíœ´ì¼ ë°˜ì˜)] ---
def get_target_date():
    today = datetime.date.today()
    
    # ê¸°ë³¸ì ìœ¼ë¡œ ì˜¤ëŠ˜ì´ ê¸ˆ(4)/í† (5)ë©´ ë‹¤ìŒì£¼ ì›”ìš”ì¼, ì•„ë‹ˆë©´ ë‚´ì¼
    if today.weekday() == 4: target = today + datetime.timedelta(days=3)
    elif today.weekday() == 5: target = today + datetime.timedelta(days=2)
    else: target = today + datetime.timedelta(days=1)

    # 2025ë…„~2029ë…„ ëŒ€í•œë¯¼êµ­ ì£¼ìš” ê³µíœ´ì¼ ë° ëŒ€ì²´ê³µíœ´ì¼ ë¦¬ìŠ¤íŠ¸
    holidays = [
        # 2025ë…„
        datetime.date(2025,1,1), datetime.date(2025,1,28), datetime.date(2025,1,29), datetime.date(2025,1,30),
        datetime.date(2025,3,1), datetime.date(2025,3,3), datetime.date(2025,5,5), datetime.date(2025,5,6),
        datetime.date(2025,6,6), datetime.date(2025,8,15), datetime.date(2025,10,3), datetime.date(2025,10,5),
        datetime.date(2025,10,6), datetime.date(2025,10,7), datetime.date(2025,10,8), datetime.date(2025,10,9), datetime.date(2025,12,25),
        # 2026ë…„
        datetime.date(2026,1,1), datetime.date(2026,2,16), datetime.date(2026,2,17), datetime.date(2026,2,18),
        datetime.date(2026,3,1), datetime.date(2026,3,2), datetime.date(2026,5,5), datetime.date(2026,5,24),
        datetime.date(2026,5,25), datetime.date(2026,6,6), datetime.date(2026,8,15), datetime.date(2026,10,3),
        datetime.date(2026,9,24), datetime.date(2026,9,25), datetime.date(2026,9,26), datetime.date(2026,10,9), datetime.date(2026,12,25),
        # 2027ë…„
        datetime.date(2027,1,1), datetime.date(2027,2,6), datetime.date(2027,2,7), datetime.date(2027,2,8),
        datetime.date(2027,2,9), datetime.date(2027,3,1), datetime.date(2027,5,5), datetime.date(2027,5,13),
        datetime.date(2027,6,6), datetime.date(2027,6,7), datetime.date(2027,8,15), datetime.date(2027,8,16),
        datetime.date(2027,10,3), datetime.date(2027,10,4), datetime.date(2027,9,14), datetime.date(2027,9,15),
        datetime.date(2027,9,16), datetime.date(2027,10,9), datetime.date(2027,12,25),
        # 2028ë…„
        datetime.date(2028,1,1), datetime.date(2028,1,26), datetime.date(2028,1,27), datetime.date(2028,1,28),
        datetime.date(2028,3,1), datetime.date(2028,5,2), datetime.date(2028,5,5), datetime.date(2028,6,6),
        datetime.date(2028,8,15), datetime.date(2028,10,3), datetime.date(2028,10,2), datetime.date(2028,10,3),
        datetime.date(2028,10,4), datetime.date(2028,10,9), datetime.date(2028,12,25),
        # 2029ë…„
        datetime.date(2029,1,1), datetime.date(2029,2,12), datetime.date(2029,2,13), datetime.date(2029,2,14),
        datetime.date(2029,3,1), datetime.date(2029,5,5), datetime.date(2029,5,7), datetime.date(2029,5,20),
        datetime.date(2029,5,21), datetime.date(2029,6,6), datetime.date(2029,8,15), datetime.date(2029,10,3),
        datetime.date(2029,9,21), datetime.date(2029,9,22), datetime.date(2029,9,23), datetime.date(2029,9,24),
        datetime.date(2029,10,9), datetime.date(2029,12,25)
    ]

    while target in holidays or target.weekday() >= 5:
        target += datetime.timedelta(days=1)
    return target

# --- [2. ë‰´ìŠ¤ ìŠ¤í¬ë˜í¼] ---
class NewsScraper:
    def __init__(self):
        self.scraper = cloudscraper.create_scraper()
        self.headers = {'User-Agent': 'Mozilla/5.0...', 'Referer': 'https://www.naver.com/'}

    def fetch_news(self, start_d, end_d, keyword):
        ds, de = start_d.strftime("%Y.%m.%d"), end_d.strftime("%Y.%m.%d")
        nso = f"so:dd,p:from{start_d.strftime('%Y%m%d')}to{end_d.strftime('%Y%m%d')}"
        all_results, seen_links = [], set()
        
        url = f"https://search.naver.com/search.naver?where=news&query=\"{keyword}\"&sort=1&pd=3&ds={ds}&de={de}&nso={nso}"
        try:
            res = self.scraper.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(res.content, 'html.parser')
            items = soup.select('a[data-heatmap-target=".tit"]')
            for t_tag in items:
                title, link = t_tag.get_text(strip=True), t_tag.get('href')
                if link in seen_links: continue
                
                card = t_tag.find_parent('div', class_=lambda c: c and ('api_subject_bx' in c or 'sds-comps' in c))
                press, date, is_naver = "ì•Œ ìˆ˜ ì—†ìŒ", "ì •ë³´ ì—†ìŒ", "n.news.naver.com" in link
                if card:
                    n_btn = card.select_one('a[href*="n.news.naver.com"]')
                    if n_btn: link, is_naver = n_btn.get('href'), True
                    p_el = card.select_one(".sds-comps-profile-info-title-text, .press_name, .info.press")
                    if p_el: press = p_el.get_text(strip=True)
                    t_el = card.select_one(".sds-comps-profile-info-subtexts, .news_info")
                    if t_el:
                        for txt in t_el.stripped_strings:
                            if ('ì „' in txt and len(txt) < 15) or ('.' in txt and len(txt) < 15 and txt[0].isdigit()):
                                date = txt; break
                seen_links.add(link)
                all_results.append({'title': title, 'link': link, 'press': press, 'time': date, 'is_naver': is_naver})
        except: pass
        return all_results

# --- [3. UI ì„¤ì •] ---
st.set_page_config(page_title="ì„œìš¸êµí†µê³µì‚¬ ìŠ¤í¬ë©", layout="wide")
st.markdown("<style>.stButton>button { width:100%; font-weight:bold; height:40px; } .news-card { background:white; padding:12px; border-radius:10px; border-left:5px solid #007bff; margin-bottom:8px; }</style>", unsafe_allow_html=True)

if 'corp_list' not in st.session_state: st.session_state.corp_list = []
if 'rel_list' not in st.session_state: st.session_state.rel_list = []
if 'search_results' not in st.session_state: st.session_state.search_results = []

target_date = get_target_date()
date_header = f"<{target_date.month}ì›” {target_date.day}ì¼({['ì›”','í™”','ìˆ˜','ëª©','ê¸ˆ','í† ','ì¼'][target_date.weekday()]}) ì¡°ê°„ ìŠ¤í¬ë©>"

st.title("ğŸš‡ ì¡°ê°„ ë‰´ìŠ¤ ìŠ¤í¬ë©")

# ìƒë‹¨ ëª©ë¡
final_output = f"{date_header}\n\n[ê³µì‚¬ ê´€ë ¨ ë³´ë„]\n"
final_output += "".join(st.session_state.corp_list) if st.session_state.corp_list else "(ë‚´ìš© ì—†ìŒ)\n"
final_output += "\n[ì² ë„ ë“± ê¸°íƒ€ ìœ ê´€ê¸°ê´€ ê´€ë ¨ ë³´ë„]\n"
final_output += "".join(st.session_state.rel_list) if st.session_state.rel_list else "(ë‚´ìš© ì—†ìŒ)\n"

st.text_area("ğŸ“‹ ì „ì²´ ë‚´ìš© ë³µì‚¬", value=final_output, height=300)

# [ì¹´ì¹´ì˜¤í†¡ ì „ì†¡ ê¸°ëŠ¥ ì¶”ê°€]
# ì´ ê¸°ëŠ¥ì€ ëª¨ë°”ì¼ì—ì„œ ì¹´ì¹´ì˜¤í†¡ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì „ë‹¬í•˜ëŠ” ë§í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
kakao_link = f"https://sharer.kakao.com/talk/friends/picker/link?app_key=YOUR_JS_KEY&display_vars=%7B%22title%22%3A%22{date_header}%22%2C%22description%22%3A%22{final_output[:100]}...%22%7D"
# ê°„ë‹¨í•˜ê²Œ 'ë³µì‚¬ í›„ ì¹´í†¡ ì—´ê¸°' í˜•íƒœë¡œ ì œì•ˆë“œë¦½ë‹ˆë‹¤.
if st.button("ğŸ’¬ ì¹´ì¹´ì˜¤í†¡ìœ¼ë¡œ ë³´ë‚´ê¸° (ì „ì²´ ë³µì‚¬ í›„ í´ë¦­)"):
    st.info("ë‚´ìš©ì„ ë³µì‚¬í•œ ë’¤ ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì¹´ì¹´ì˜¤í†¡ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    components.html(f"""
        <script>
        window.open('kakaolink://send?text=' + encodeURIComponent(`{final_output}`));
        </script>
    """, height=0)

st.divider()

# ê²€ìƒ‰ ë° ê²°ê³¼
with st.expander("ğŸ” ê²€ìƒ‰ ì„¤ì •", expanded=True):
    keyword = st.text_input("í‚¤ì›Œë“œ", value="ì„œìš¸êµí†µê³µì‚¬")
    filter_opt = st.radio("í•„í„°", ["ë„¤ì´ë²„ ê¸°ì‚¬", "ëª¨ë‘ ë³´ê¸°"], horizontal=True)

if st.button("ğŸš€ ê²€ìƒ‰ ì‹œì‘", type="primary"):
    with st.spinner('ê²€ìƒ‰ ì¤‘...'):
        st.session_state.search_results = NewsScraper().fetch_news(datetime.date.today()-datetime.timedelta(days=1), datetime.date.today(), keyword)

if st.session_state.search_results:
    res_list = st.session_state.search_results
    if filter_opt == "ë„¤ì´ë²„ ê¸°ì‚¬": res_list = [r for r in res_list if r['is_naver']]
    
    for i, res in enumerate(res_list):
        st.markdown(f"<div class='news-card'><b>[{res['press']}]</b> {res['title']}<br><small>{res['time']}</small></div>", unsafe_allow_html=True)
        b1, b2, b3 = st.columns(3)
        with b1: st.link_button("ğŸ”— ì›ë¬¸", res['link'])
        with b2:
            if st.button("ğŸ¢ ê³µì‚¬ ì¶”ê°€", key=f"c_{i}"):
                # ê¸°ì‚¬ ì‚¬ì´ ì—”í„° í•œ ì¹¸ ì¶”ê°€ (\n\n)
                item = f"ã…‡ {res['title']}_{res['press']}\n{res['link']}\n\n"
                if item not in st.session_state.corp_list:
                    st.session_state.corp_list.append(item); st.rerun()
        with b3:
            if st.button("ğŸš† ìœ ê´€ ì¶”ê°€", key=f"r_{i}"):
                item = f"ã…‡ {res['title']}_{res['press']}\n{res['link']}\n\n"
                if item not in st.session_state.rel_list:
                    st.session_state.rel_list.append(item); st.rerun()