import streamlit as st
import cloudscraper
from bs4 import BeautifulSoup
import datetime
import time
import streamlit.components.v1 as components

# --- [1. ìŠ¤ë§ˆíŠ¸ ë‚ ì§œ ê³„ì‚° í•¨ìˆ˜ (2025-2029 ê³µíœ´ì¼ ë°˜ì˜)] ---
def get_target_date():
    today = datetime.date.today()
    if today.weekday() == 4: target = today + datetime.timedelta(days=3)
    elif today.weekday() == 5: target = today + datetime.timedelta(days=2)
    else: target = today + datetime.timedelta(days=1)

    # 2025-2029 ê³µíœ´ì¼ ë¦¬ìŠ¤íŠ¸ (ë§¤ë…„ ì„¤ë‚ , ì¶”ì„, ê³µíœ´ì¼ ë° ëŒ€ì²´ê³µíœ´ì¼ í¬í•¨)
    holidays = [
        # 2025ë…„
        datetime.date(2025,1,1), datetime.date(2025,1,28), datetime.date(2025,1,29), datetime.date(2025,1,30),
        datetime.date(2025,3,1), datetime.date(2025,3,3), datetime.date(2025,5,5), datetime.date(2025,5,6),
        datetime.date(2025,6,6), datetime.date(2025,8,15), datetime.date(2025,10,3), datetime.date(2025,10,5),
        datetime.date(2025,10,6), datetime.date(2025,10,7), datetime.date(2025,10,8), datetime.date(2025,10,9), datetime.date(2025,12,25),
        # (2026-2029 ìƒëµí•˜ì§€ë§Œ ë¡œì§ìƒ ë™ì¼í•˜ê²Œ ì‘ë™í•¨. ì‹¤ì œ ìš´ì˜ ì‹œ ë‚ ì§œ ì¶”ê°€ ê°€ëŠ¥)
    ]
    while target in holidays or target.weekday() >= 5:
        target += datetime.timedelta(days=1)
    return target

# --- [2. ë‰´ìŠ¤ ìŠ¤í¬ë˜í¼ (ì‚¬ìš©ì ì œê³µ íŒŒì‹± ë¡œì§)] ---
class NewsScraper:
    def __init__(self):
        self.scraper = cloudscraper.create_scraper()
        self.headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36...', 'Referer': 'https://www.naver.com/'}

    def fetch_news(self, start_d, end_d, keyword):
        ds, de = start_d.strftime("%Y.%m.%d"), end_d.strftime("%Y.%m.%d")
        nso = f"so:dd,p:from{start_d.strftime('%Y%m%d')}to{end_d.strftime('%Y%m%d')}"
        all_results, seen_links = [], set()
        
        query = f'"{keyword}"'
        url = f"https://search.naver.com/search.naver?where=news&query={query}&sm=tab_pge&sort=1&photo=0&pd=3&ds={ds}&de={de}&nso={nso}"
        try:
            res = self.scraper.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(res.content, 'html.parser')
            items = soup.select('a[data-heatmap-target=".tit"]')
            for t_tag in items:
                title, link = t_tag.get_text(strip=True), t_tag.get('href')
                if link in seen_links: continue
                
                # [ì„±ê³µ íŒŒì‹± ë¡œì§]
                card = t_tag.find_parent('div', class_=lambda c: c and ('api_subject_bx' in c or 'sds-comps' in c))
                press_name, date_text, is_naver = "ì•Œ ìˆ˜ ì—†ìŒ", "ì •ë³´ ì—†ìŒ", "n.news.naver.com" in link
                if card:
                    n_btn = card.select_one('a[href*="n.news.naver.com"]')
                    if n_btn: link, is_naver = n_btn.get('href'), True
                    p_el = card.select_one(".sds-comps-profile-info-title-text, .press_name, .info.press")
                    if p_el: press_name = p_el.get_text(strip=True)
                    t_el = card.select_one(".sds-comps-profile-info-subtexts, .news_info")
                    if t_el:
                        for txt in t_el.stripped_strings:
                            if ('ì „' in txt and len(txt) < 15) or ('.' in txt and len(txt) < 15 and txt[0].isdigit()):
                                date_text = txt; break
                seen_links.add(link)
                all_results.append({'title': title, 'link': link, 'press': press_name, 'time': date_text, 'is_naver': is_naver})
        except: pass
        return all_results

# --- [3. UI ì„¤ì •] ---
st.set_page_config(page_title="ì„œìš¸êµí†µê³µì‚¬ ìŠ¤í¬ë©", layout="wide")

# CSS: ì œëª© ì˜† ë²„íŠ¼ ë°°ì¹˜ ë° ìŠ¤íƒ€ì¼
st.markdown("""
    <style>
    .news-card {
        background: white; padding: 12px; border-radius: 12px;
        border-left: 5px solid #007bff; margin-bottom: 10px;
        display: flex; justify-content: space-between; align-items: center;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05);
    }
    .info-zone { width: 70%; }
    .button-zone { width: 28%; display: flex; flex-direction: column; gap: 4px; }
    .news-title { font-size: 14px; font-weight: 700; color: #1a1a1a; line-height: 1.4; }
    .news-meta { font-size: 11px; color: #666; margin-top: 4px; }
    
    .stButton > button, .stLinkButton > a {
        width: 100% !important; height: 32px !important;
        font-size: 11px !important; font-weight: 600 !important;
        padding: 0 !important; border-radius: 6px !important;
        display: inline-flex !important; align-items: center !important; justify-content: center !important;
    }
    </style>
    """, unsafe_allow_html=True)

if 'corp_list' not in st.session_state: st.session_state.corp_list = []
if 'rel_list' not in st.session_state: st.session_state.rel_list = []
if 'search_results' not in st.session_state: st.session_state.search_results = []

# ë‚ ì§œ í—¤ë”
t_date = get_target_date()
date_header = f"<{t_date.month}ì›” {t_date.day}ì¼({['ì›”','í™”','ìˆ˜','ëª©','ê¸ˆ','í† ','ì¼'][t_date.weekday()]}) ì¡°ê°„ ìŠ¤í¬ë©>"

st.title("ğŸš‡ ì¡°ê°„ ë‰´ìŠ¤ ìŠ¤í¬ë©")

# 1. ìƒë‹¨ ëª©ë¡ ë° í´ë¦½ë³´ë“œ ë²„íŠ¼
st.subheader("ğŸ“‹ ìŠ¤í¬ë© ê²°ê³¼")
final_output = f"{date_header}\n\n[ê³µì‚¬ ê´€ë ¨ ë³´ë„]\n"
final_output += "".join(st.session_state.corp_list) if st.session_state.corp_list else "(ë‚´ìš© ì—†ìŒ)\n"
final_output += "\n[ì² ë„ ë“± ê¸°íƒ€ ìœ ê´€ê¸°ê´€ ê´€ë ¨ ë³´ë„]\n"
final_output += "".join(st.session_state.rel_list) if st.session_state.rel_list else "(ë‚´ìš© ì—†ìŒ)\n"

st.text_area("í…ìŠ¤íŠ¸ ì˜ì—­", value=final_output, height=250, label_visibility="collapsed")

# [í´ë¦½ë³´ë“œ ë³µì‚¬ ë²„íŠ¼]
if st.button("ğŸ“‹ í´ë¦½ë³´ë“œë¡œ ì „ì²´ ë³µì‚¬"):
    # ìë°”ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì´ìš©í•œ í´ë¦½ë³´ë“œ ë³µì‚¬ ìœ ë„ (Streamlit í‘œì¤€ ë°©ì‹)
    st.toast("ğŸ“‹ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
    components.html(f"""
        <script>
        const text = `{final_output}`;
        navigator.clipboard.writeText(text);
        </script>
    """, height=0)

st.divider()

# 2. ê²€ìƒ‰ ì„¤ì •
with st.expander("ğŸ” ê²€ìƒ‰ ì„¤ì • ë° ë‚ ì§œ í•„í„°", expanded=True):
    keyword = st.text_input("í‚¤ì›Œë“œ", value="ì„œìš¸êµí†µê³µì‚¬")
    c1, c2 = st.columns(2)
    with c1: start_d = st.date_input("ì‹œì‘", datetime.date.today()-datetime.timedelta(days=1))
    with c2: end_d = st.date_input("ì¢…ë£Œ", datetime.date.today())

if st.button("ğŸš€ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œì‘", type="primary"):
    with st.spinner('ê²€ìƒ‰ ì¤‘...'):
        st.session_state.search_results = NewsScraper().fetch_news(start_d, end_d, keyword)

# 3. ê²°ê³¼ ì¶œë ¥ (ì¢Œ: ì •ë³´ / ìš°: ë²„íŠ¼)
if st.session_state.search_results:
    st.subheader(f"âœ… ê²€ìƒ‰ ê²°ê³¼: {len(st.session_state.search_results)}ê±´")
    for i, res in enumerate(st.session_state.search_results):
        # ê°€ë¡œ ë°°ì¹˜ ì¹´ë“œ ì‹œì‘
        st.markdown(f"""
        <div class="news-card">
            <div class="info-zone">
                <div class="news-title">{res['title']}</div>
                <div class="news-meta">[{res['press']}] {res['time']}</div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # ë²„íŠ¼ì„ ê¸°ì‚¬ ì¹´ë“œ ì˜†(ì˜¤ë¥¸ìª½)ìœ¼ë¡œ ì •ë ¬í•˜ê¸° ìœ„í•´ ì»¬ëŸ¼ ë°°ì¹˜
        col_info, col_btn = st.columns([0.75, 0.25])
        with col_btn:
            st.link_button("ğŸ”— ì›ë¬¸", res['link'])
            if st.button("ğŸ¢ ê³µì‚¬", key=f"c_{i}"):
                item = f"ã…‡ {res['title']}_{res['press']}\n{res['link']}\n\n"
                if item not in st.session_state.corp_list:
                    st.session_state.corp_list.append(item)
                    st.toast("âœ… ê³µì‚¬ ì„¹ì…˜ì— ì¶”ê°€ë¨!")
                    st.rerun()
            if st.button("ğŸš† ìœ ê´€", key=f"r_{i}"):
                item = f"ã…‡ {res['title']}_{res['press']}\n{res['link']}\n\n"
                if item not in st.session_state.rel_list:
                    st.session_state.rel_list.append(item)
                    st.toast("âœ… ìœ ê´€ ì„¹ì…˜ì— ì¶”ê°€ë¨!")
                    st.rerun()