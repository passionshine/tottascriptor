import streamlit as st
import cloudscraper
from bs4 import BeautifulSoup
import datetime
import time

# --- [ë‰´ìŠ¤ ìŠ¤í¬ë˜í¼ í´ë˜ìŠ¤] ---
class NewsScraper:
    def fetch_news(self, start_datetime, end_datetime, keyword, photo_value):
        ds, de = start_datetime.strftime("%Y.%m.%d"), end_datetime.strftime("%Y.%m.%d")
        nso = f"so:dd,p:from{start_datetime.strftime('%Y%m%d')}to{end_datetime.strftime('%Y%m%d')}"
        
        all_results = []
        seen_links = set()
        scraper = cloudscraper.create_scraper()
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': 'https://www.naver.com/'
        }

        # ìµœëŒ€ 5í˜ì´ì§€ íƒìƒ‰
        for page in range(1, 6):
            start_index = (page - 1) * 10 + 1
            query = f'"{keyword}"'
            url = f"https://search.naver.com/search.naver?where=news&query={query}&sm=tab_pge&sort=1&photo={photo_value}&pd=3&ds={ds}&de={de}&nso={nso}&start={start_index}"
            
            try:
                response = scraper.get(url, headers=headers, timeout=10)
                soup = BeautifulSoup(response.content, 'html.parser')
                items = soup.select('a[data-heatmap-target=".tit"]')
                if not items: break

                for t_tag in items:
                    title = t_tag.get_text(strip=True)
                    original_link = t_tag.get('href')
                    
                    # ì¹´ë“œ ì»¨í…Œì´ë„ˆ íƒìƒ‰
                    card = None
                    curr = t_tag
                    for _ in range(5):
                        if curr.parent:
                            curr = curr.parent
                            if curr.select_one(".sds-comps-profile") or curr.select_one(".news_info"):
                                card = curr
                                break
                    
                    # [ë¡œì§] ë„¤ì´ë²„ ë‰´ìŠ¤ ë§í¬ ìš°ì„  íƒìƒ‰
                    final_link = original_link
                    is_naver = "n.news.naver.com" in original_link
                    
                    press_name = "ì•Œ ìˆ˜ ì—†ìŒ"
                    date_text = "ë‚ ì§œ ì •ë³´ ì—†ìŒ"

                    if card:
                        # ë„¤ì´ë²„ ì¸ë§í¬ê°€ ë”°ë¡œ ìˆëŠ”ì§€ í™•ì¸
                        naver_btn = card.select_one('a[href*="n.news.naver.com"]')
                        if naver_btn:
                            final_link = naver_btn.get('href')
                            is_naver = True

                        press_el = card.select_one(".sds-comps-profile-info-title-text, .press_name, .info.press")
                        if press_el: press_name = press_el.get_text(strip=True)
                        
                        subtext_area = card.select_one(".sds-comps-profile-info-subtexts, .news_info")
                        if subtext_area:
                            for txt in subtext_area.stripped_strings:
                                if ('ì „' in txt and len(txt) < 15) or ('.' in txt and len(txt) < 15 and txt[0].isdigit()):
                                    date_text = txt
                                    break

                    if final_link in seen_links: continue
                    seen_links.add(final_link)
                    all_results.append({
                        'title': title, 'link': final_link, 
                        'press': press_name, 'time': date_text, 'is_naver': is_naver
                    })
                time.sleep(0.3)
            except: break
        return all_results

# --- [Streamlit ì›¹ UI] ---
st.set_page_config(page_title="ì„œìš¸êµí†µê³µì‚¬ ìŠ¤í¬ë©", layout="wide")

# ëª¨ë°”ì¼ 1ì¤„ ë ˆì´ì•„ì›ƒ ë° ë²„íŠ¼ ìŠ¤íƒ€ì¼ CSS
st.markdown("""
    <style>
    .stButton>button { border-radius: 5px; height: 32px; padding: 0px 10px; font-size: 13px !important; }
    .news-card { background: white; padding: 12px; border-radius: 8px; border-left: 5px solid #007bff; margin-bottom: 5px; }
    /* ë²„íŠ¼ 1ì¤„ ì •ë ¬ì„ ìœ„í•œ ê°€ë¡œ ë°°ì—´ */
    .button-row { display: flex; gap: 8px; margin-top: 8px; }
    .link-btn { 
        display: inline-flex; align-items: center; justify-content: center;
        text-decoration: none; background: #f0f2f6; color: #31333F;
        border-radius: 5px; height: 32px; padding: 0px 10px; font-size: 13px; font-weight: 500; border: 1px solid #d1d5db;
    }
    </style>
    """, unsafe_allow_html=True)

if 'scrap_list' not in st.session_state: st.session_state.scrap_list = []
if 'search_results' not in st.session_state: st.session_state.search_results = []

st.title("ğŸš‡ ë‰´ìŠ¤ ìŠ¤í¬ë© (Mobile)")

# 1. ìŠ¤í¬ë© ëª©ë¡ (ìµœìƒë‹¨)
st.subheader("ğŸ“‹ ìŠ¤í¬ë© ëª©ë¡")
if st.session_state.scrap_list:
    final_text = "".join(st.session_state.scrap_list)
    st.text_area("ë³µì‚¬í•˜ê¸°", value=final_text, height=150)
    if st.button("ğŸ—‘ï¸ ë¹„ìš°ê¸°"):
        st.session_state.scrap_list = []
        st.rerun()
else:
    st.caption("ê¸°ì‚¬ë¥¼ ì¶”ê°€í•˜ë©´ ì—¬ê¸°ì— ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")

st.divider()

# 2. ê²€ìƒ‰ ì„¤ì •
with st.expander("ğŸ” ê²€ìƒ‰ ì¡°ê±´", expanded=True):
    keyword = st.text_input("í‚¤ì›Œë“œ", value="ì„œìš¸êµí†µê³µì‚¬")
    col1, col2 = st.columns(2)
    with col1: start_date = st.date_input("ì‹œì‘", datetime.date.today() - datetime.timedelta(days=1))
    with col2: end_date = st.date_input("ì¢…ë£Œ", datetime.date.today())
    
    # [ì¶”ê°€] í•„í„° ì„ íƒ (ê¸°ë³¸ê°’: ë„¤ì´ë²„ ê¸°ì‚¬)
    filter_choice = st.radio("ê²€ìƒ‰ ë²”ìœ„", ["ë„¤ì´ë²„ ê¸°ì‚¬", "ì–¸ë¡ ì‚¬ ìì²´ê¸°ì‚¬", "ëª¨ë‘ ë³´ê¸°"], index=0, horizontal=True)

if st.button("ğŸš€ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤í–‰", type="primary"):
    scraper = NewsScraper()
    with st.spinner('ê²€ìƒ‰ ì¤‘...'):
        results = scraper.fetch_news(start_date, end_date, keyword, 0)
        st.session_state.search_results = results

# 3. ê²€ìƒ‰ ê²°ê³¼ (í•„í„° ì ìš©)
if st.session_state.search_results:
    # í•„í„°ë§ ë¡œì§
    if filter_choice == "ë„¤ì´ë²„ ê¸°ì‚¬":
        display_results = [r for r in st.session_state.search_results if r['is_naver']]
    elif filter_choice == "ì–¸ë¡ ì‚¬ ìì²´ê¸°ì‚¬":
        display_results = [r for r in st.session_state.search_results if not r['is_naver']]
    else:
        display_results = st.session_state.search_results

    st.subheader(f"âœ… ê²°ê³¼: {len(display_results)}ê±´")
    for i, res in enumerate(display_results):
        with st.container():
            st.markdown(f"""
            <div class="news-card">
                <strong>[{res['press']}]</strong> {res['title']}<br>
                <small style="color:gray;">{res['time']} {'(ë„¤ì´ë²„)' if res['is_naver'] else ''}</small>
            </div>
            """, unsafe_allow_html=True)
            
            # ë²„íŠ¼ 1ì¤„ ë ˆì´ì•„ì›ƒ (columns ì‚¬ìš©)
            btn_col1, btn_col2 = st.columns([1, 1])
            with btn_col1:
                # ì›ë¬¸ë§í¬ ë²„íŠ¼ì„ ì‘ê²Œ ë§Œë“¤ê¸° ìœ„í•´ HTML ë²„íŠ¼ ì‚¬ìš©
                st.markdown(f'<a href="{res["link"]}" target="_blank" class="link-btn">ğŸ”— ì›ë¬¸ë³´ê¸°</a>', unsafe_allow_html=True)
            with btn_col2:
                if st.button("â• ì¶”ê°€", key=f"add_{i}"):
                    item = f"ã…‡ {res['title']}_{res['press']}\n{res['link']}\n\n"
                    if item not in st.session_state.scrap_list:
                        st.session_state.scrap_list.append(item)
                        st.toast("ì¶”ê°€ë¨!")
                        st.rerun()