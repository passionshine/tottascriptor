import streamlit as st
import cloudscraper
from bs4 import BeautifulSoup
import datetime
import time
import re
import json
import streamlit.components.v1 as components

# --- [1. ìŠ¤ë§ˆíŠ¸ ë‚ ì§œ ê³„ì‚° í•¨ìˆ˜] ---
def get_target_date():
    today = datetime.date.today()
    if today.weekday() == 4: target = today + datetime.timedelta(days=3)
    elif today.weekday() == 5: target = today + datetime.timedelta(days=2)
    else: target = today + datetime.timedelta(days=1)

    holidays = [
        datetime.date(2025,1,1), datetime.date(2025,1,28), datetime.date(2025,1,29), datetime.date(2025,1,30),
        datetime.date(2025,3,1), datetime.date(2025,3,3), datetime.date(2025,5,5), datetime.date(2025,5,6),
        datetime.date(2025,6,6), datetime.date(2025,8,15), datetime.date(2025,10,3), datetime.date(2025,10,5),
        datetime.date(2025,10,6), datetime.date(2025,10,7), datetime.date(2025,10,8), datetime.date(2025,10,9), datetime.date(2025,12,25),
    ]
    while target in holidays or target.weekday() >= 5:
        target += datetime.timedelta(days=1)
    return target

# --- [2. ë‰´ìŠ¤ ìŠ¤í¬ë˜í¼ (JSON íŒŒì‹± ë°©ì‹ ì ìš©)] ---
class NewsScraper:
    def __init__(self):
        self.scraper = cloudscraper.create_scraper()
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': 'https://www.naver.com/'
        }

    def fetch_news(self, start_d, end_d, keyword, max_articles):
        ds, de = start_d.strftime("%Y.%m.%d"), end_d.strftime("%Y.%m.%d")
        nso = f"so:dd,p:from{start_d.strftime('%Y%m%d')}to{end_d.strftime('%Y%m%d')}"
        all_results = []
        seen_titles = set() # ì¤‘ë³µ ì œê±°ìš©
        
        query = f'"{keyword}"'
        max_pages = (max_articles // 10) + 1
        
        for page in range(max_pages):
            if len(all_results) >= max_articles: break
            
            start_val = (page * 10) + 1
            url = f"https://search.naver.com/search.naver?where=news&query={query}&sm=tab_pge&sort=1&photo=0&pd=3&ds={ds}&de={de}&nso={nso}&start={start_val}"
            
            try:
                res = self.scraper.get(url, headers=self.headers, timeout=10)
                soup = BeautifulSoup(res.content, 'html.parser')
                
                # [í•µì‹¬ ë¡œì§] entry.bootstrap ì•ˆì˜ JSON ë°ì´í„° ì¶”ì¶œ
                scripts = soup.find_all('script')
                json_data = None
                
                for script in scripts:
                    if 'entry.bootstrap' in script.text:
                        # ì •ê·œì‹ìœ¼ë¡œ entry.bootstrap(..., { JSON }); íŒ¨í„´ì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
                        # (?<=...): ê¸ì •í˜• í›„ë°© íƒìƒ‰, document.getElementById(...) ë’¤ì— ì˜¤ëŠ” {,} íŒ¨í„´ ì°¾ê¸°
                        match = re.search(r'entry\.bootstrap\(document\.getElementById\(".*?"\), ({.*})\);', script.text)
                        if match:
                            try:
                                json_str = match.group(1)
                                json_data = json.loads(json_str)
                                break
                            except:
                                continue

                if not json_data:
                    # JSON ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ í˜ì´ì§€ë¡œ (í˜¹ì€ HTML íŒŒì‹± í´ë°± ê°€ëŠ¥í•˜ë‚˜ ì—¬ê¸°ì„  íŒ¨ìŠ¤)
                    continue

                # JSON êµ¬ì¡° íƒìƒ‰: body -> props -> children ë¦¬ìŠ¤íŠ¸
                try:
                    items_list = json_data.get('body', {}).get('props', {}).get('children', [])
                except:
                    items_list = []

                for item in items_list:
                    if len(all_results) >= max_articles: break
                    
                    # í…œí”Œë¦¿ IDê°€ newsItemì¸ ê²ƒë§Œ ì²˜ë¦¬ (ê´‘ê³  ë“± ì œì™¸)
                    if item.get('templateId') != 'newsItem':
                        continue
                        
                    props = item.get('props', {})
                    
                    # 1. ì œëª© ë° ì›ë³¸ ë§í¬
                    raw_title = props.get('title', '')
                    # HTML íƒœê·¸ ì œê±° (mark íƒœê·¸ ë“±)
                    clean_title = re.sub('<[^<]+?>', '', raw_title)
                    original_link = props.get('titleHref', '')
                    
                    # ì¤‘ë³µ ì œê±°
                    if clean_title in seen_titles: continue
                    seen_titles.add(clean_title)

                    # 2. ì–¸ë¡ ì‚¬ ì •ë³´
                    source_info = props.get('sourceProfile', {})
                    press_name = source_info.get('title', 'ì•Œ ìˆ˜ ì—†ìŒ')

                    # 3. ì¶”ê°€ ì •ë³´ (ì§€ë©´, ë„¤ì´ë²„ë‰´ìŠ¤ ë§í¬ ë“±)
                    sub_texts = props.get('subTexts', [])
                    
                    is_naver = False
                    final_link = original_link
                    paper_info = ""

                    for sub in sub_texts:
                        # (1) ë„¤ì´ë²„ ë‰´ìŠ¤ ë§í¬ í™•ì¸
                        # JSON êµ¬ì¡°ìƒ "text": "ë„¤ì´ë²„ë‰´ìŠ¤" ì´ê³  "textHref"ê°€ ì¡´ì¬í•¨
                        if sub.get('text') == 'ë„¤ì´ë²„ë‰´ìŠ¤' and sub.get('textHref'):
                            is_naver = True
                            final_link = sub.get('textHref')
                        
                        # (2) ì§€ë©´ ì •ë³´ í™•ì¸ (ì˜ˆ: "A10ë©´", "1ë©´")
                        txt = sub.get('text', '')
                        if txt and re.search(r'^\s*[A-Za-z]*\d+ë©´', txt):
                            paper_info = f" ({txt})"

                    # ì œëª©ì— ì§€ë©´ ì •ë³´ ë¶™ì´ê¸°
                    full_title = f"{clean_title}{paper_info}"

                    all_results.append({
                        'title': full_title,
                        'link': final_link,
                        'press': press_name,
                        'is_naver': is_naver
                    })

                time.sleep(0.1)
                
            except Exception as e:
                print(f"Error processing page {page}: {e}")
                continue
                
        return all_results

# --- [3. UI ì„¤ì •] ---
st.set_page_config(page_title="Totta Scriptor", layout="wide")

st.markdown("""
    <style>
    /* 1. ìˆ˜í‰ ë¸”ë¡ ê°„ê²© ì œì–´ */
    [data-testid="stHorizontalBlock"] {
        gap: 4px !important;
        align-items: center !important; 
    }

    /* 2. ì»¬ëŸ¼ íŒ¨ë”© ìµœì í™” */
    div[data-testid="column"], div[data-testid="stColumn"] {
        padding: 0px !important;
        min-width: 0px !important;
        display: flex !important;
        justify-content: center !important; 
    }

    /* 3. ë²„íŠ¼ ê¸°ë³¸ ìŠ¤íƒ€ì¼ */
    .stButton { width: 100% !important; margin: 0 !important; }
    .stButton > button {
        width: 100% !important;
        height: 38px !important;
        padding: 0px 5px !important;
        font-size: 12px !important;
        font-weight: bold !important;
        border-radius: 6px !important;
        border: 1px solid #ddd !important;
    }
    .stLinkButton > a {
        width: 100% !important;
        height: 38px !important;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 11px !important;
    }

    /* 4. ë²„íŠ¼ ìƒ‰ìƒ ê°•ì œ ì§€ì • */
    div[data-testid="stHorizontalBlock"] > div[data-testid="column"]:nth-child(3) button,
    div[data-testid="stHorizontalBlock"] > div[data-testid="stColumn"]:nth-child(3) button {
        background-color: #e3f2fd !important;
        color: #1565c0 !important;
        border: 1px solid #90caf9 !important;
    }
    div[data-testid="stHorizontalBlock"] > div[data-testid="column"]:nth-child(3) button:hover,
    div[data-testid="stHorizontalBlock"] > div[data-testid="stColumn"]:nth-child(3) button:hover {
        background-color: #bbdefb !important;
    }

    div[data-testid="stHorizontalBlock"] > div[data-testid="column"]:nth-child(4) button,
    div[data-testid="stHorizontalBlock"] > div[data-testid="stColumn"]:nth-child(4) button {
        background-color: #e8f5e9 !important;
        color: #2e7d32 !important;
        border: 1px solid #a5d6a7 !important;
    }
    div[data-testid="stHorizontalBlock"] > div[data-testid="column"]:nth-child(4) button:hover,
    div[data-testid="stHorizontalBlock"] > div[data-testid="stColumn"]:nth-child(4) button:hover {
        background-color: #c8e6c9 !important;
    }

    /* ë‰´ìŠ¤ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .news-card {
        padding: 8px 12px;
        border-radius: 6px;
        border-left: 4px solid #007bff;
        box-shadow: 0 1px 1px rgba(0,0,0,0.05);
        display: flex;
        flex-direction: column;
        justify-content: center;
        height: 100%;
    }
    .bg-white { background: white !important; }
    .bg-scraped { background: #eee !important; border-left: 4px solid #888 !important; opacity: 0.7; }
    .news-title { font-size: 17px !important; font-weight: 600; color: #333; line-height: 1.2; margin-bottom: 2px; }
    .news-meta { font-size: 14px !important; color: #666; }
    
    /* ì„¹ì…˜ í—¤ë” ìŠ¤íƒ€ì¼ */
    .section-header {
        font-size: 18px;
        font-weight: 700;
        color: #333;
        margin-top: 25px;
        margin-bottom: 15px;
        border-bottom: 2px solid #007bff;
        padding-bottom: 5px;
        display: inline-block;
    }
    </style>
    """, unsafe_allow_html=True)

# ì„¸ì…˜ ê´€ë¦¬
for key in ['corp_list', 'rel_list', 'search_results']:
    if key not in st.session_state: st.session_state[key] = []

st.title("ğŸš‡ ë˜íƒ€ ìŠ¤í¬ë¦½í„°")

# 1. ìŠ¤í¬ë© ê²°ê³¼ ì˜ì—­
t_date = get_target_date()
date_header = f"<{t_date.month}ì›” {t_date.day}ì¼ ì¡°ê°„ ìŠ¤í¬ë©>"
final_output = f"{date_header}\n\n[ê³µì‚¬ ê´€ë ¨ ë³´ë„]\n" + "".join(st.session_state.corp_list) + "\n[ìœ ê´€ê¸°ê´€ ê´€ë ¨ ë³´ë„]\n" + "".join(st.session_state.rel_list)

# ê²°ê³¼ì°½
dynamic_height = max(180, (final_output.count('\n') + 1) * 25)
st.text_area("ğŸ“‹ ìŠ¤í¬ë© ê²°ê³¼ (ì „ì²´ í…ìŠ¤íŠ¸)", value=final_output, height=dynamic_height)

# ë²„íŠ¼ ì˜ì—­
c_a, c_b = st.columns(2)
with c_a:
    if st.button("ğŸ“‹ í…ìŠ¤íŠ¸ ë³µì‚¬", use_container_width=True):
        st.toast("ë³µì‚¬ ì™„ë£Œ!")
        components.html(f"<script>navigator.clipboard.writeText(`{final_output}`);</script>", height=0)
with c_b:
    if st.button("ğŸ—‘ï¸ ì „ì²´ ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.corp_list, st.session_state.rel_list = [], []
        st.rerun()

# ê´€ë¦¬ ì˜ì—­
with st.expander("ğŸ› ï¸ ìŠ¤í¬ë© í•­ëª© ê°œë³„ ê´€ë¦¬", expanded=False):
    st.write("**ğŸ¢ ê³µì‚¬ ë³´ë„ ëª©ë¡**")
    for idx, item in enumerate(st.session_state.corp_list):
        col_txt, col_del = st.columns([0.85, 0.15])
        with col_txt: st.caption(item.split('\n')[0])
        with col_del: 
            if st.button("ì‚­ì œ", key=f"del_c_{idx}"):
                st.session_state.corp_list.pop(idx)
                st.rerun()
    
    st.write("**ğŸš† ìœ ê´€ê¸°ê´€ ë³´ë„ ëª©ë¡**")
    for idx, item in enumerate(st.session_state.rel_list):
        col_txt, col_del = st.columns([0.85, 0.15])
        with col_txt: st.caption(item.split('\n')[0])
        with col_del:
            if st.button("ì‚­ì œ", key=f"del_r_{idx}"):
                st.session_state.rel_list.pop(idx)
                st.rerun()

st.divider()

# 2. ê²€ìƒ‰ ì„¤ì •
with st.expander("ğŸ” ë‰´ìŠ¤ ê²€ìƒ‰ ì„¤ì •", expanded=True):
    keyword = st.text_input("ê²€ìƒ‰ì–´", value="ì„œìš¸êµí†µê³µì‚¬")
    col_d1, col_d2 = st.columns(2)
    with col_d1: start_d = st.date_input("ì‹œì‘ì¼", datetime.date.today() - datetime.timedelta(days=1))
    with col_d2: end_d = st.date_input("ì¢…ë£Œì¼", datetime.date.today())
    max_a = st.slider("ìµœëŒ€ ê¸°ì‚¬ ìˆ˜", 10, 100, 30)
    if st.button("ğŸš€ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œì‘", type="primary", use_container_width=True):
        with st.spinner('ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³  JSON ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...'):
            st.session_state.search_results = NewsScraper().fetch_news(start_d, end_d, keyword, max_a)
        st.rerun()

# 3. ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ í•¨ìˆ˜ (ê³µí†µ ì‚¬ìš©)
def display_news_section(title, articles, section_key):
    st.markdown(f'<div class="section-header">{title} ({len(articles)}ê±´)</div>', unsafe_allow_html=True)
    
    if not articles:
        st.caption("ê²€ìƒ‰ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    for i, res in enumerate(articles):
        # ìŠ¤í¬ë© í…ìŠ¤íŠ¸ ìƒì„±: ì œëª©_ì–¸ë¡ ì‚¬ (ì¤„ë°”ê¿ˆ) URL
        item_check = f"ã…‡ {res['title']}_{res['press']}\n{res['link']}\n\n"
        is_scraped = (item_check in st.session_state.corp_list) or (item_check in st.session_state.rel_list)
        bg_class = "bg-scraped" if is_scraped else "bg-white"

        with st.container():
            col1, col2, col3, col4 = st.columns([0.73, 0.09, 0.09, 0.09])
            
            with col1:
                st.markdown(f'''
                <div class="news-card {bg_class}">
                    <div class="news-title">{res["title"]}</div>
                    <div class="news-meta">[{res["press"]}] {"(ìŠ¤í¬ë©ë¨)" if is_scraped else ""}</div>
                </div>
                ''', unsafe_allow_html=True)
            
            with col2:
                st.link_button("ì›ë¬¸ë³´ê¸°", res['link'])
            with col3:
                # keyì— section_keyë¥¼ ì¶”ê°€í•˜ì—¬ ID ì¶©ëŒ ë°©ì§€
                if st.button("ê³µì‚¬ë³´ë„", key=f"c_{section_key}_{i}"):
                    if item_check not in st.session_state.corp_list:
                        st.session_state.corp_list.append(item_check)
                        st.toast("ğŸ¢ ê³µì‚¬ê´€ë ¨ ë³´ë„ ì¶”ê°€ ì™„ë£Œ!"); time.sleep(0.1); st.rerun()
                    else: st.toast("âš ï¸ ì´ë¯¸ ì¶”ê°€ë¨")
            with col4:
                if st.button("ìœ ê´€ê¸°ê´€", key=f"r_{section_key}_{i}"):
                    if item_check not in st.session_state.rel_list:
                        st.session_state.rel_list.append(item_check)
                        st.toast("ğŸš† ìœ ê´€ê¸°ê´€ ë³´ë„ ì¶”ê°€ ì™„ë£Œ!"); time.sleep(0.1); st.rerun()
                    else: st.toast("âš ï¸ ì´ë¯¸ ì¶”ê°€ë¨")
        
        st.markdown("<hr style='margin: 3px 0; border: none; border-top: 1px solid #f0f0f0;'>", unsafe_allow_html=True)

# 4. ê²°ê³¼ ì¶œë ¥ ë¡œì§
if st.session_state.search_results:
    naver_news = [item for item in st.session_state.search_results if item.get('is_naver', False)]
    other_news = [item for item in st.session_state.search_results if not item.get('is_naver', False)]
    
    display_news_section("ğŸŸ¢ ë„¤ì´ë²„ ë‰´ìŠ¤", naver_news, "naver")
    st.write("") 
    display_news_section("ğŸŒ ì–¸ë¡ ì‚¬ ìì²´ ê¸°ì‚¬", other_news, "press")